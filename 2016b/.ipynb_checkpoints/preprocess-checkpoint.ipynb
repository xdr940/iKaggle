{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "from path import Path\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/home/roit/datasets/kaggle/2016b')\n",
    "dump_path = root/'dump'\n",
    "ge_info = root/'gene_info'\n",
    "\n",
    "df_train = pd.read_csv(root/\"genotype.csv\",sep=' ')#空格分割\n",
    "#df_y = pd.read_csv(root/'phenotype.csv')\n",
    "#df_train_small = pd.read_csv(dump_path/'genotype_100_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read gen_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_small = pd.read_csv(dump_path/'genotype_100_100.csv')\n",
    "type_rs=[]\n",
    "for col in df_train_small.columns:\n",
    "    for i in range(len(df_train_small)):\n",
    "        \n",
    "        if 'A' in df_train_small[col][i] and 'T'in df_train_small[col][i]:\n",
    "            type_rs.append('AT')\n",
    "            break\n",
    "        elif 'A' in df_train_small[col][i] and 'C'in df_train_small[col][i]:\n",
    "            type_rs.append('AC')\n",
    "            break\n",
    "        elif 'A' in df_train_small[col][i] and 'G'in df_train_small[col][i]:\n",
    "            type_rs.append('AT')\n",
    "            break\n",
    "        elif 'A' in df_train_small[col][i] and 'T'in df_train_small[col][i]:\n",
    "            type_rs.append('AT')\n",
    "            break\n",
    "        elif 'A' in df_train_small[col][i] and 'T'in df_train_small[col][i]:\n",
    "            type_rs.append('AT')\n",
    "            break\n",
    "        elif 'A' in df_train_small[col][i] and 'T'in df_train_small[col][i]:\n",
    "            type_rs.append('AT')\n",
    "            break\n",
    "\n",
    "\n",
    "IN=['AA','CC','GG','AT','TA','AG','GA','AC','CA','CG','CT','GT','TT','GG','CC']\n",
    "OU=[0,   0,    0,   1,   1,   1,   1,   1,   1,   1,    1,   1,   2,   2,   2]\n",
    "for col in df_train_small.columns:\n",
    "    df_train_small[col]=df_train_small[col].replace(IN,OU)\n",
    "df_train_small.to_csv(dump_path/'genotype_small_coded_.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rs3094315', 'rs3131972', 'rs3131969', 'rs1048488', 'rs12562034',\n",
       "       'rs12124819', 'rs4040617', 'rs2980300', 'rs4970383', 'rs4475691',\n",
       "       ...\n",
       "       'rs10914386', 'rs6688664', 'rs6702129', 'rs7548805', 'rs7532525',\n",
       "       'rs7546536', 'rs4261154', 'rs4615888', 'rs10798854', 'rs7545865'],\n",
       "      dtype='object', length=9445)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-90-5416b6207587>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-90-5416b6207587>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    labels[i] = 'ID_'+str(i)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "labels =[]\n",
    "for i in range(100):\n",
    "    try:\n",
    "        labels[i] = 'ID_'+str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  9 60]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('demo_3.csv')\n",
    "ser = pd.read_csv('group.csv',dtype=\"category\")#读取为分类变量\n",
    "#import pandas_profiling\n",
    "#df.profile_report(title ='demo')\n",
    "'''\n",
    "demo.csv\n",
    "a,b,c,d\n",
    "0,2,1,0\n",
    "1,1,0,2\n",
    "2,2,2,0\n",
    "1,0,2,1\n",
    "1,0,1,0\n",
    "1,1,0,1\n",
    "\n",
    "\n",
    "group.csv\n",
    "\n",
    "group\n",
    "0\n",
    "0\n",
    "0\n",
    "1\n",
    "1\n",
    "1\n",
    "\n",
    "'''\n",
    "\n",
    "def observisions2chi2s(ser, df):\n",
    "    \"\"\"\n",
    "        计数资料统计，根据df的每一列得到一个四格表,用来做chi2_contingency\n",
    "    :param ser:分组series\n",
    "    :param df:观测表 r行为r号观测结果, l为 l号位点碱基对值\n",
    "    :return:四格表list\n",
    "    \"\"\"\n",
    "    assert (len(ser) == len(df))  # 分组标签是否和df记录数量一致\n",
    "\n",
    "    nums_group = ser.describe().iloc[1, 0]  # unique\n",
    "\n",
    "    arr_list = []\n",
    "    ret_arry = np.zeros([nums_group, 3])\n",
    "    col = df.columns\n",
    "    for col in df.columns:  # 遍历列\n",
    "        for r in range(len(ser)):  # 遍历行\n",
    "            g = int(ser.iloc[r, 0])\n",
    "            v = int(df[col][r])\n",
    "            ret_arry[g, v] += 1\n",
    "        arr_list.append(ret_arry)\n",
    "        ret_arry=np.zeros([nums_group, 3])\n",
    "    return arr_list\n",
    "\n",
    "\n",
    "ret_arrys = observisions2chi2s(ser, df)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roit/wkpgs/Anaconda3/envs/pt/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sorted_cols_series = pd.Series(sorted_cols)\n",
    "sorted_cols_series.to_csv(dump_path/'sorted_cols_series.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AB'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'A'+'B'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
